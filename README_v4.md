# DATA_BOT v4 - Enterprise Archiving Platform

![DATA_BOT v4](https://img.shields.io/badge/version-4.0.0-blue.svg)
![Docker](https://img.shields.io/badge/docker-ready-green.svg)
![Kubernetes](https://img.shields.io/badge/kubernetes-supported-brightgreen.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

Une plateforme d'archivage internet de niveau entreprise avec fonctionnalitÃ©s avancÃ©es de ML, clustering, et dÃ©ploiement cloud-native.

## ğŸ¯ Nouvelles FonctionnalitÃ©s v4

### âœ… ImplÃ©mentÃ©es

#### 1. ğŸ”§ Interface d'Administration ComplÃ¨te
- Dashboard en temps rÃ©el avec mÃ©triques avancÃ©es
- Gestion complÃ¨te des ressources et catÃ©gories
- Monitoring systÃ¨me intÃ©grÃ©
- Outils d'administration et maintenance
- Interface responsive et intuitive

#### 2. ğŸ” Support OpenSearch comme Alternative Ã  Elasticsearch
- Moteur de recherche open-source compatible
- Basculement automatique entre ES et OpenSearch
- API unifiÃ©e pour la recherche
- Performance optimisÃ©e pour de gros volumes

#### 3. ğŸ§¬ Clustering Automatique des RÃ©sultats
- Algorithmes multiples (HDBSCAN, K-means, Agglomerative, DBSCAN)
- Clustering intelligent des rÃ©sultats de recherche
- Visualisation et exploration des clusters
- Recommandations basÃ©es sur la similaritÃ©

#### 4. ğŸš€ API GraphQL ComplÃ¨te
- Schema GraphQL pour toutes les fonctionnalitÃ©s
- RequÃªtes, mutations et subscriptions
- Interface GraphQL Playground intÃ©grÃ©e
- Support des requÃªtes complexes et relations

#### 5. ğŸ¤– Machine Learning pour CatÃ©gorisation Automatique
- Classification automatique du contenu
- Support de modÃ¨les multiples (Naive Bayes, Transformers)
- EntraÃ®nement et Ã©valuation de modÃ¨les
- CatÃ©gorisation en temps rÃ©el

#### 6. â˜¸ï¸ Support Kubernetes Complet
- Manifests Kubernetes optimisÃ©s
- DÃ©ploiement multi-environnement
- Auto-scaling et haute disponibilitÃ©
- Monitoring et observabilitÃ©

#### 7. ğŸ³ Dockerisation 100%
- Images Docker optimisÃ©es multi-stage
- Docker Compose pour dÃ©veloppement
- Orchestration complÃ¨te des services
- Configuration par variables d'environnement

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Interface â”‚    â”‚  Admin Interfaceâ”‚    â”‚  GraphQL API    â”‚
â”‚   (Port 8080)   â”‚    â”‚   (Port 8082)   â”‚    â”‚   (Port 8083)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     API Server v4       â”‚
                    â”‚    (FastAPI Core)       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ML Categorizerâ”‚    â”‚  Result Clusterer   â”‚    â”‚ OpenSearch Managerâ”‚
â”‚   (scikit-learnâ”‚    â”‚    (HDBSCAN/etc)    â”‚    â”‚  (Alternative ES) â”‚
â”‚   transformers)â”‚    â”‚                     â”‚    â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                         â”‚                         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Database Manager     â”‚
                    â”‚   (PostgreSQL/SQLite)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation et DÃ©ploiement

### Option 1: Docker Compose (RecommandÃ© pour dÃ©veloppement)

```bash
# Cloner le repository
git clone https://github.com/EpicSanDev/DATA_BOT.git
cd DATA_BOT

# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier le statut
docker-compose ps
```

**Services disponibles:**
- Interface principale: http://localhost:8080
- Interface d'administration: http://localhost:8082
- API GraphQL: http://localhost:8083/graphql
- Monitoring (Grafana): http://localhost:3000

### Option 2: Kubernetes (Production)

```bash
# DÃ©ployer sur Kubernetes
python src/kubernetes_deployer.py deploy --environment production

# VÃ©rifier le dÃ©ploiement
kubectl get pods -n databot-v4

# AccÃ©der aux services
kubectl port-forward -n databot-v4 svc/databot-service 8080:8080
```

### Option 3: Installation locale

```bash
# Installer les dÃ©pendances
pip install -r requirements.txt -r requirements_v3.txt -r requirements_v4.txt

# DÃ©marrer v4
python main_v4.py --mode server --enable-admin --enable-graphql --enable-opensearch
```

## ğŸ”§ Configuration

### Variables d'Environnement

```env
# Configuration gÃ©nÃ©rale
ENVIRONMENT=development
DEBUG=true

# Base de donnÃ©es
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=databot_v4
POSTGRES_USER=databot
POSTGRES_PASSWORD=your_password

# Moteurs de recherche
USE_OPENSEARCH=true
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9201
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200

# Machine Learning
ENABLE_ML_CATEGORIZATION=true
ML_MODEL=distilbert-base-uncased
CONFIDENCE_THRESHOLD=0.3

# Clustering
ENABLE_RESULT_CLUSTERING=true
CLUSTERING_ALGORITHM=hdbscan
MIN_CLUSTER_SIZE=3

# Ports des services
API_PORT=8080
ADMIN_PORT=8082
GRAPHQL_PORT=8083

# Kubernetes
KUBERNETES_NAMESPACE=databot-v4
```

## ğŸ“š Utilisation

### 1. Interface d'Administration

```bash
# AccÃ©der au dashboard admin
http://localhost:8082
```

**FonctionnalitÃ©s disponibles:**
- ğŸ“Š Dashboard avec mÃ©triques en temps rÃ©el
- ğŸ” Recherche et exploration avancÃ©e
- ğŸ“š Gestion complÃ¨te des ressources
- ğŸ·ï¸ Gestion des catÃ©gories et tags
- ğŸ§¬ Configuration et lancement de clustering
- ğŸ¤– EntraÃ®nement et gestion des modÃ¨les ML
- ğŸ“ˆ Monitoring systÃ¨me complet

### 2. API GraphQL

```bash
# AccÃ©der au playground GraphQL
http://localhost:8083/graphql
```

**Exemples de requÃªtes:**

```graphql
# Recherche avec clustering
query SearchWithClustering {
  search(
    query: "intelligence artificielle"
    enableClustering: true
    limit: 20
  ) {
    results {
      resources {
        id
        title
        url
        categories
      }
      total
    }
    clusters {
      id
      name
      description
      size
      keywords
    }
    executionTime
  }
}

# CatÃ©gorisation automatique
mutation CategorizeResource {
  categorizeResource(id: 123) {
    id
    categories
    title
  }
}

# Clustering des ressources
mutation ClusterResources {
  clusterResources(algorithm: "hdbscan") {
    id
    name
    size
    coherenceScore
    keywords
  }
}
```

### 3. API REST v4

```bash
# Recherche avancÃ©e
curl -X POST http://localhost:8080/api/v4/search/advanced \
  -H "Content-Type: application/json" \
  -d '{
    "query": "machine learning",
    "search_engine": "opensearch",
    "enable_clustering": true,
    "clustering_algorithm": "hdbscan",
    "limit": 20
  }'

# CatÃ©gorisation ML
curl -X POST http://localhost:8080/api/v4/ml/categorize \
  -H "Content-Type: application/json" \
  -d '{
    "confidence_threshold": 0.3,
    "max_categories": 5,
    "auto_save": true
  }'

# Lancement de clustering
curl -X POST http://localhost:8080/api/v4/clustering/run \
  -H "Content-Type: application/json" \
  -d '{
    "algorithm": "hdbscan",
    "min_cluster_size": 3
  }'
```

## ğŸ¤– Machine Learning

### CatÃ©gorisation Automatique

Le systÃ¨me utilise plusieurs approches pour la catÃ©gorisation:

1. **Naive Bayes + TF-IDF** pour la classification rapide
2. **Transformers** (zero-shot) pour la prÃ©cision
3. **RÃ¨gles heuristiques** pour les domaines spÃ©cialisÃ©s

```python
# Exemple d'utilisation
await ml_categorizer.categorize_resource(resource)
# â†’ ['Technology', 'AI/ML', 'Programming']
```

### Clustering Intelligent

Algorithmes supportÃ©s:
- **HDBSCAN**: Clustering basÃ© sur la densitÃ© (recommandÃ©)
- **K-means**: Clustering par centroÃ¯des
- **Agglomerative**: Clustering hiÃ©rarchique
- **DBSCAN**: Clustering par densitÃ© avec paramÃ¨tres fixes

```python
# Clustering automatique des rÃ©sultats de recherche
clustering_result = await result_clusterer.cluster_search_results(
    search_results, query="intelligence artificielle"
)
```

## ğŸ” Moteurs de Recherche

### OpenSearch vs Elasticsearch

Le systÃ¨me supporte automatiquement:
- **OpenSearch** (recommandÃ©): Open source, performant
- **Elasticsearch**: Support complet avec fallback
- **Base de donnÃ©es**: Recherche basique en fallback

Configuration automatique:
```python
# Le systÃ¨me choisit automatiquement le meilleur moteur disponible
search_engine = await determine_search_engine("auto")
# â†’ "opensearch" | "elasticsearch" | "database"
```

## â˜¸ï¸ DÃ©ploiement Kubernetes

### Manifests Inclus

- `k8s/01-namespace-config.yaml`: Namespace et configuration
- `k8s/02-databot-deployment.yaml`: Application principale
- `k8s/03-databases.yaml`: PostgreSQL et Redis
- `k8s/04-search-engines.yaml`: ES, OpenSearch, Qdrant

### Commandes Utiles

```bash
# DÃ©ploiement complet
python src/kubernetes_deployer.py deploy --environment production

# VÃ©rification du statut
python src/kubernetes_deployer.py status

# Scaling
python src/kubernetes_deployer.py scale --deployment databot-v4 --replicas 5

# Suppression
python src/kubernetes_deployer.py delete
```

### Monitoring

Services de monitoring inclus:
- **Prometheus**: Collecte de mÃ©triques
- **Grafana**: Visualisation des donnÃ©es
- **Health checks**: VÃ©rification automatique de santÃ©

## ğŸ“Š Monitoring et ObservabilitÃ©

### MÃ©triques Disponibles

- Utilisation CPU/MÃ©moire/Disque
- Nombre de requÃªtes par seconde
- Temps de rÃ©ponse des API
- Statut des composants
- Performance des algorithmes ML

### Endpoints de Monitoring

```bash
# SantÃ© gÃ©nÃ©rale
GET /health

# SantÃ© dÃ©taillÃ©e de tous les composants
GET /api/v4/health/detailed

# MÃ©triques systÃ¨me
GET /api/v4/monitoring/metrics

# Logs systÃ¨me
GET /api/v4/monitoring/logs?level=INFO&limit=100
```

## ğŸ”§ DÃ©veloppement

### Structure du Projet v4

```
DATA_BOT/
â”œâ”€â”€ main_v4.py                 # Point d'entrÃ©e principal v4
â”œâ”€â”€ requirements_v4.txt        # DÃ©pendances v4
â”œâ”€â”€ Dockerfile                 # Image Docker multi-stage
â”œâ”€â”€ docker-compose.yml         # Orchestration complÃ¨te
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api_server_v4.py      # Serveur API Ã©tendu
â”‚   â”œâ”€â”€ admin_interface.py    # Interface d'administration
â”‚   â”œâ”€â”€ opensearch_manager.py # Gestionnaire OpenSearch
â”‚   â”œâ”€â”€ ml_categorizer.py     # CatÃ©goriseur ML
â”‚   â”œâ”€â”€ result_clusterer.py   # Clustering automatique
â”‚   â”œâ”€â”€ graphql_server.py     # Serveur GraphQL
â”‚   â””â”€â”€ kubernetes_deployer.py # DÃ©ployeur K8s
â”œâ”€â”€ k8s/                      # Manifests Kubernetes
â”‚   â”œâ”€â”€ 01-namespace-config.yaml
â”‚   â”œâ”€â”€ 02-databot-deployment.yaml
â”‚   â”œâ”€â”€ 03-databases.yaml
â”‚   â””â”€â”€ 04-search-engines.yaml
â””â”€â”€ monitoring/               # Configuration monitoring
    â”œâ”€â”€ prometheus.yml
    â””â”€â”€ grafana/
```

### Tests

```bash
# Tests unitaires
python -m pytest tests/

# Tests d'intÃ©gration
python test_v4_integration.py

# Tests de performance
python test_v4_performance.py
```

## ğŸ“ˆ Performance

### Benchmarks v4

- **Recherche**: 50-200ms (selon moteur et taille index)
- **CatÃ©gorisation ML**: 100-500ms par ressource
- **Clustering**: 1-30s (selon algorithme et taille dataset)
- **GraphQL**: 10-100ms par requÃªte

### Optimisations

- Cache Redis pour requÃªtes frÃ©quentes
- Indexation asynchrone en arriÃ¨re-plan
- Batch processing pour operations ML
- Connection pooling pour bases de donnÃ©es

## ğŸš§ Roadmap Futur

### Version 4.1 (Q2 2024)
- [ ] Support multi-tenancy
- [ ] API de webhooks
- [ ] IntÃ©gration LangChain avancÃ©e
- [ ] Support des modÃ¨les custom

### Version 4.2 (Q3 2024)
- [ ] Interface mobile native
- [ ] Support streaming en temps rÃ©el
- [ ] IntÃ©gration cloud providers (AWS, GCP, Azure)
- [ ] Analytics avancÃ©es

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit les changements (`git commit -am 'Ajout nouvelle fonctionnalitÃ©'`)
4. Push la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. CrÃ©er une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ’¬ Support

- **Documentation**: [Wiki du projet](https://github.com/EpicSanDev/DATA_BOT/wiki)
- **Issues**: [GitHub Issues](https://github.com/EpicSanDev/DATA_BOT/issues)
- **Discussions**: [GitHub Discussions](https://github.com/EpicSanDev/DATA_BOT/discussions)

## ğŸ¯ Migration depuis v3

La v4 est entiÃ¨rement compatible avec la v3. Les donnÃ©es existantes sont automatiquement migrÃ©es:

```bash
# Migration automatique depuis v3
python main_v4.py --mode migrate-from-v3

# VÃ©rification post-migration
python main_v4.py --mode verify-migration
```

---

**ğŸ¤– DATA_BOT v4 - L'avenir de l'archivage internet intelligent!**

![Enterprise Ready](https://img.shields.io/badge/Enterprise-Ready-success.svg)
![Cloud Native](https://img.shields.io/badge/Cloud-Native-blue.svg)
![AI Powered](https://img.shields.io/badge/AI-Powered-purple.svg)